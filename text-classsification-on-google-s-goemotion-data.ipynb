{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1956405,"sourceType":"datasetVersion","datasetId":1060121}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport string\nimport emoji\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport torch\nfrom transformers import BertForSequenceClassification\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:27:40.922941Z","iopub.execute_input":"2025-02-14T19:27:40.923243Z","iopub.status.idle":"2025-02-14T19:28:01.602445Z","shell.execute_reply.started":"2025-02-14T19:27:40.923197Z","shell.execute_reply":"2025-02-14T19:28:01.601824Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import WordNetLemmatizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:01.603888Z","iopub.execute_input":"2025-02-14T19:28:01.604477Z","iopub.status.idle":"2025-02-14T19:28:02.257258Z","shell.execute_reply.started":"2025-02-14T19:28:01.604452Z","shell.execute_reply":"2025-02-14T19:28:02.256560Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_data = pd.read_csv(\"../input/goemotions/data/train.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])\nvalid_data = pd.read_csv(\"../input/goemotions/data/dev.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])\ntest_data = pd.read_csv(\"/kaggle/input/goemotions/data/test.tsv\", sep='\\t', header=None, names=['Text', 'Class', 'ID'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.258185Z","iopub.execute_input":"2025-02-14T19:28:02.258471Z","iopub.status.idle":"2025-02-14T19:28:02.425095Z","shell.execute_reply.started":"2025-02-14T19:28:02.258431Z","shell.execute_reply":"2025-02-14T19:28:02.424464Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.425824Z","iopub.execute_input":"2025-02-14T19:28:02.426046Z","iopub.status.idle":"2025-02-14T19:28:02.444072Z","shell.execute_reply.started":"2025-02-14T19:28:02.426027Z","shell.execute_reply":"2025-02-14T19:28:02.443212Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID\n0  My favourite food is anything I didn't have to...    27  eebbqej\n1  Now if he does off himself, everyone will thin...    27  ed00q6i\n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj\n3                        To make her feel threatened    14  ed7ypvh\n4                             Dirty Southern Wankers     3  ed0bdzj","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.444921Z","iopub.execute_input":"2025-02-14T19:28:02.445250Z","iopub.status.idle":"2025-02-14T19:28:02.477370Z","shell.execute_reply.started":"2025-02-14T19:28:02.445177Z","shell.execute_reply":"2025-02-14T19:28:02.476590Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 43410 entries, 0 to 43409\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   Text    43410 non-null  object\n 1   Class   43410 non-null  object\n 2   ID      43410 non-null  object\ndtypes: object(3)\nmemory usage: 1017.5+ KB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_data['Class List'] = train_data['Class'].apply(lambda x: x.split(','))\ntrain_data['Class Length'] = train_data['Class List'].apply(lambda x: len(x))\n\nvalid_data['Class List'] = valid_data['Class'].apply(lambda x: x.split(','))\nvalid_data['Class Length'] = valid_data['Class List'].apply(lambda x: len(x))\n\ntest_data['Class List'] = test_data['Class'].apply(lambda x: x.split(','))\ntest_data['Class Length'] = test_data['Class List'].apply(lambda x: len(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.479396Z","iopub.execute_input":"2025-02-14T19:28:02.479642Z","iopub.status.idle":"2025-02-14T19:28:02.526739Z","shell.execute_reply.started":"2025-02-14T19:28:02.479622Z","shell.execute_reply":"2025-02-14T19:28:02.525908Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_data[\"Class Length\"].value_counts()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.528110Z","iopub.execute_input":"2025-02-14T19:28:02.528314Z","iopub.status.idle":"2025-02-14T19:28:02.535403Z","shell.execute_reply.started":"2025-02-14T19:28:02.528297Z","shell.execute_reply":"2025-02-14T19:28:02.534582Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Class Length\n1    36308\n2     6541\n3      532\n4       28\n5        1\nName: count, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"with open('../input/goemotions/data/ekman_mapping.json') as file:\n    ekman_mapping = json.load(file)\nekman_mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.536145Z","iopub.execute_input":"2025-02-14T19:28:02.536344Z","iopub.status.idle":"2025-02-14T19:28:02.552135Z","shell.execute_reply.started":"2025-02-14T19:28:02.536327Z","shell.execute_reply":"2025-02-14T19:28:02.551497Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'anger': ['anger', 'annoyance', 'disapproval'],\n 'disgust': ['disgust'],\n 'fear': ['fear', 'nervousness'],\n 'joy': ['joy',\n  'amusement',\n  'approval',\n  'excitement',\n  'gratitude',\n  'love',\n  'optimism',\n  'relief',\n  'pride',\n  'admiration',\n  'desire',\n  'caring'],\n 'sadness': ['sadness', 'disappointment', 'embarrassment', 'grief', 'remorse'],\n 'surprise': ['surprise', 'realization', 'confusion', 'curiosity']}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"emotion_file = open(\"../input/goemotions/data/emotions.txt\", \"r\")\nemotion_list = emotion_file.read()\nemotion_list = emotion_list.split(\"\\n\")\nprint(emotion_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.552960Z","iopub.execute_input":"2025-02-14T19:28:02.553270Z","iopub.status.idle":"2025-02-14T19:28:02.561871Z","shell.execute_reply.started":"2025-02-14T19:28:02.553241Z","shell.execute_reply":"2025-02-14T19:28:02.561133Z"}},"outputs":[{"name":"stdout","text":"['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def idx2class(idx_list):\n    arr = []\n    for i in idx_list:\n        arr.append(emotion_list[int(i)])\n    return arr\ntrain_data['Emotions'] = train_data['Class List'].apply(idx2class)\nvalid_data['Emotions'] = valid_data['Class List'].apply(idx2class)\ntest_data['Emotions'] = test_data['Class List'].apply(idx2class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.562835Z","iopub.execute_input":"2025-02-14T19:28:02.563069Z","iopub.status.idle":"2025-02-14T19:28:02.894852Z","shell.execute_reply.started":"2025-02-14T19:28:02.563051Z","shell.execute_reply":"2025-02-14T19:28:02.893962Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.895772Z","iopub.execute_input":"2025-02-14T19:28:02.896027Z","iopub.status.idle":"2025-02-14T19:28:02.917356Z","shell.execute_reply.started":"2025-02-14T19:28:02.896008Z","shell.execute_reply":"2025-02-14T19:28:02.916618Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID  \\\n0  My favourite food is anything I didn't have to...    27  eebbqej   \n1  Now if he does off himself, everyone will thin...    27  ed00q6i   \n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj   \n3                        To make her feel threatened    14  ed7ypvh   \n4                             Dirty Southern Wankers     3  ed0bdzj   \n\n  Class List  Class Length     Emotions  \n0       [27]             1    [neutral]  \n1       [27]             1    [neutral]  \n2        [2]             1      [anger]  \n3       [14]             1       [fear]  \n4        [3]             1  [annoyance]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n      <th>Class List</th>\n      <th>Class Length</th>\n      <th>Emotions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n      <td>[2]</td>\n      <td>1</td>\n      <td>[anger]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n      <td>[14]</td>\n      <td>1</td>\n      <td>[fear]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n      <td>[3]</td>\n      <td>1</td>\n      <td>[annoyance]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"emotion_to_idx = {emotion: i for i, emotion in enumerate(emotion_list)}\n\n# Function to convert list of emotions to binary vector\ndef encode_emotions(emotions):\n    vector = [0] * len(emotion_to_idx)\n    for emotion in emotions:\n        idx = emotion_to_idx[emotion]\n        vector[idx] = 1\n    return vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.918124Z","iopub.execute_input":"2025-02-14T19:28:02.918389Z","iopub.status.idle":"2025-02-14T19:28:02.930116Z","shell.execute_reply.started":"2025-02-14T19:28:02.918367Z","shell.execute_reply":"2025-02-14T19:28:02.929382Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_data['emotion_vector'] = train_data['Emotions'].apply(encode_emotions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.930735Z","iopub.execute_input":"2025-02-14T19:28:02.930940Z","iopub.status.idle":"2025-02-14T19:28:02.976928Z","shell.execute_reply.started":"2025-02-14T19:28:02.930923Z","shell.execute_reply":"2025-02-14T19:28:02.976373Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.977610Z","iopub.execute_input":"2025-02-14T19:28:02.977874Z","iopub.status.idle":"2025-02-14T19:28:02.990138Z","shell.execute_reply.started":"2025-02-14T19:28:02.977848Z","shell.execute_reply":"2025-02-14T19:28:02.989403Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                Text Class       ID  \\\n0  My favourite food is anything I didn't have to...    27  eebbqej   \n1  Now if he does off himself, everyone will thin...    27  ed00q6i   \n2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj   \n3                        To make her feel threatened    14  ed7ypvh   \n4                             Dirty Southern Wankers     3  ed0bdzj   \n\n  Class List  Class Length     Emotions  \\\n0       [27]             1    [neutral]   \n1       [27]             1    [neutral]   \n2        [2]             1      [anger]   \n3       [14]             1       [fear]   \n4        [3]             1  [annoyance]   \n\n                                      emotion_vector  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n      <th>ID</th>\n      <th>Class List</th>\n      <th>Class Length</th>\n      <th>Emotions</th>\n      <th>emotion_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>My favourite food is anything I didn't have to...</td>\n      <td>27</td>\n      <td>eebbqej</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Now if he does off himself, everyone will thin...</td>\n      <td>27</td>\n      <td>ed00q6i</td>\n      <td>[27]</td>\n      <td>1</td>\n      <td>[neutral]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n      <td>2</td>\n      <td>eezlygj</td>\n      <td>[2]</td>\n      <td>1</td>\n      <td>[anger]</td>\n      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>To make her feel threatened</td>\n      <td>14</td>\n      <td>ed7ypvh</td>\n      <td>[14]</td>\n      <td>1</td>\n      <td>[fear]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dirty Southern Wankers</td>\n      <td>3</td>\n      <td>ed0bdzj</td>\n      <td>[3]</td>\n      <td>1</td>\n      <td>[annoyance]</td>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.texts = dataframe['Text']\n        self.labels = dataframe['emotion_vector'].tolist()\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, index):\n        text = self.texts.iloc[index]\n        label = self.labels[index]\n        \n        encoding = self.tokenizer(\n            text,\n            padding='max_length',\n            truncation=True,\n            max_length = self.max_len\n        )\n        return {\n            'input_ids': torch.tensor(encoding['input_ids']),\n            'attention_mask': torch.tensor(encoding['attention_mask']),\n            'labels': torch.tensor(label, dtype=torch.float)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:02.990893Z","iopub.execute_input":"2025-02-14T19:28:02.991164Z","iopub.status.idle":"2025-02-14T19:28:03.002718Z","shell.execute_reply.started":"2025-02-14T19:28:02.991143Z","shell.execute_reply":"2025-02-14T19:28:03.001860Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ndataset = EmotionDataset(train_data, tokenizer, 512)\nloader = DataLoader(dataset, batch_size=16, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:03.003641Z","iopub.execute_input":"2025-02-14T19:28:03.003852Z","iopub.status.idle":"2025-02-14T19:28:03.798831Z","shell.execute_reply.started":"2025-02-14T19:28:03.003834Z","shell.execute_reply":"2025-02-14T19:28:03.798026Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"727645e7a34c40199f4ff1c37a40d8fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92688adba817413baaddd421c946be36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1f7a340f1864d398547d80f7fadf063"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3de320a7cbb44bc896d48dd249e322e1"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"num_labels = 28 \nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n\n# Use Binary Cross-Entropy Loss for multi-label classification\nloss_fn = nn.BCEWithLogitsLoss()\n\n# Optimizer remains the same\noptimizer = optim.AdamW(model.parameters(), lr=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:03.799698Z","iopub.execute_input":"2025-02-14T19:28:03.799899Z","iopub.status.idle":"2025-02-14T19:28:06.232216Z","shell.execute_reply.started":"2025-02-14T19:28:03.799881Z","shell.execute_reply":"2025-02-14T19:28:06.231394Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a4224c36afd41668f99fc74a3f4c632"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Ensure you set the device to cuda:0 as the default\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Move the model to cuda:0 before applying DataParallel\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:06.234510Z","iopub.execute_input":"2025-02-14T19:28:06.234722Z","iopub.status.idle":"2025-02-14T19:28:06.679058Z","shell.execute_reply.started":"2025-02-14T19:28:06.234703Z","shell.execute_reply":"2025-02-14T19:28:06.678387Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"pip install torch_xla","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T19:28:06.679851Z","iopub.execute_input":"2025-02-14T19:28:06.680048Z","iopub.status.idle":"2025-02-14T19:28:15.859832Z","shell.execute_reply.started":"2025-02-14T19:28:06.680030Z","shell.execute_reply":"2025-02-14T19:28:15.858943Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_xla\n  Downloading torch_xla-2.6.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (21 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from torch_xla) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_xla) (1.26.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from torch_xla) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_xla) (2.32.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch_xla) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch_xla) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch_xla) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch_xla) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch_xla) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch_xla) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_xla) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_xla) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch_xla) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch_xla) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch_xla) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch_xla) (2024.2.0)\nDownloading torch_xla-2.6.0-cp310-cp310-manylinux_2_28_x86_64.whl (93.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.6/93.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_xla\nSuccessfully installed torch_xla-2.6.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import torch_xla.core.xla_model as xm\ndevice = xm.xla_device()\nmodel = YourModel().to(device) \nmodel = torch.nn.DataParallel(model)\n\n# Training loop\nfor epoch in range(10):  # Replace 10 with the number of epochs you want\n    model.train()\n    epoch_loss = 0\n    for batch in loader:\n        optimizer.zero_grad()\n\n        # Move the input data to the appropriate device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].float().to(device)  # Ensure labels are float for BCEWithLogitsLoss\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        \n        # Compute loss\n        loss = loss_fn(outputs.logits, labels)\n        \n        # Backward pass\n        loss.backward()\n        \n        # Optimization step\n        optimizer.step()\n        \n        # Track loss for this epoch\n        epoch_loss += loss.item()\n    \n    # Average epoch loss\n    avg_loss = epoch_loss / len(loader)\n    print(f\"Epoch {epoch+1} Loss: {avg_loss}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_directory = \"/kaggle/working/bert_emotion_classifier\"\n# Save the model\nif torch.cuda.device_count() > 1:\n    model.module.save_pretrained(output_directory)\nelse:\n    model.save_pretrained(output_directory)\n# Save the tokenizer\ntokenizer.save_pretrained(output_directory)\nprint(f\"Model saved as: {output_directory}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}